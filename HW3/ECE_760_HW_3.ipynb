{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "jxvUDZSroCdO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 1**"
      ],
      "metadata": {
        "id": "20F4JKh_ZZ29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCgA8BwNW05c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_table('D2z.txt', sep=\" \", header=None, names=[\"x1\", \"x2\", \"y\"])\n",
        "\n",
        "X, y = data.drop([data.columns[-1]], axis=1), data[data.columns[-1]]\n",
        "\n",
        "testdata = {'x1': [], 'x2': [], 'y': []}\n",
        "feature_1 = np.arange(-2.0, 2.1, 0.1)\n",
        "feature_2 = np.arange(-2.0, 2.1, 0.1)\n",
        "for i in feature_1:\n",
        "    for j in feature_2:\n",
        "        testdata['x1'].append(i)\n",
        "        testdata['x2'].append(j)\n",
        "        testdata['y'].append(-1)\n",
        "\n",
        "test = pd.DataFrame(testdata)\n",
        "X_test = test.drop([test.columns[-1]], axis=1)\n",
        "for i in X_test.index:\n",
        "    distances = []\n",
        "    for j in X.index:\n",
        "        distances.append(np.linalg.norm(X_test.iloc[i] - X.iloc[j]))\n",
        "    min_index = distances.index(min(distances))\n",
        "    test.at[i, \"y\"] = data.iloc[min_index][\"y\"]\n",
        "    \n",
        "\n",
        "plt.scatter(test['x1'], test['x2'], c=['r' if i == 1 else 'y' for i in test['y']]  ,alpha=0.2)\n",
        "plt.scatter(data['x1'], data['x2'], c=['r' if i == 1 else 'y' for i in data['y']], marker='x')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 2**"
      ],
      "metadata": {
        "id": "MZvQxICGYhdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(train,test,fold):\n",
        "  X_test, y_test = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "  X_train, y_train = train.drop([train.columns[-1]], axis=1), train[train.columns[-1]]\n",
        "  X_train = X_train.iloc[:,1:].to_numpy()\n",
        "  y_train = y_train.to_numpy()\n",
        "  X_test = X_test.iloc[:,1:].to_numpy()\n",
        "  y_test = y_test.to_numpy()\n",
        "  y_hat=[]\n",
        "  train = train.to_numpy\n",
        "  for test in X_test:\n",
        "      distances = [np.linalg.norm(test - x) for x in X_train]\n",
        "      min_index = distances.index(min(distances))\n",
        "      y_hat.append(y_train[min_index])\n",
        "  precision = precision_score(y_test, y_hat)\n",
        "  recall = recall_score(y_test, y_hat)\n",
        "  accuracy = accuracy_score(y_test, y_hat)\n",
        "  return precision,accuracy,recall\n",
        "\n",
        "data = pd.read_csv('emails.csv',sep=',')\n",
        "for i in range(0,5):\n",
        "  test = data.iloc[i*1000:i*1000 + 1000, :]\n",
        "  train = data.drop(test.index)\n",
        "  precision,accuracy,recall = knn(train,test,i*1000)\n",
        "  print(\"Fold \",i+1)\n",
        "  print(\"Accuracy: \",accuracy)\n",
        "  print(\"Precision: \",precision)\n",
        "  print(\"Recall: \",recall)\n",
        "  print(\"---------------------------------\")"
      ],
      "metadata": {
        "id": "w4Gz8Ms8YzVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3**"
      ],
      "metadata": {
        "id": "2GEQue7qvLnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression():\n",
        "    def __init__(self, alpha, iterations):\n",
        "        self.alpha = alpha\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.m, self.n = X.shape\n",
        "        self.W = np.zeros(self.n)\n",
        "        self.b = 0\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        for i in range(self.iterations):\n",
        "            self.weights_update()\n",
        "        return self\n",
        "\n",
        "    def weights_update(self):\n",
        "        A = 1 / (1 + np.exp(- (self.X.dot(self.W) + self.b)))\n",
        "\n",
        "        temp = (A - self.Y.T)\n",
        "        temp = np.reshape(temp, self.m)\n",
        "        dW = np.dot(self.X.T, temp) / self.m\n",
        "        db = np.sum(temp) / self.m\n",
        "\n",
        "        self.W = self.W - self.alpha * dW\n",
        "        self.b = self.b - self.alpha * db\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        P = 1 / (1 + np.exp(- (X.dot(self.W) + self.b)))\n",
        "        Y = np.where(P > 0.5, 1, 0)\n",
        "        return Y\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv('emails.csv', sep=',')\n",
        "for i in range(0, 5):\n",
        "    test = data.iloc[i*1000:i*1000 + 1000, :]\n",
        "    train = data.drop(test.index)\n",
        "\n",
        "    X_train = train.iloc[:, 1:-1].values\n",
        "    X_test = test.iloc[:, 1:-1].values\n",
        "    y_train = train.iloc[:, -1:].values\n",
        "    y_test = test.iloc[:, -1:].values.ravel()\n",
        "\n",
        "    clf = LogisticRegression(alpha=0.01, iterations=3000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_hat = clf.predict(X_test)\n",
        "    precision = precision_score(y_test, y_hat)\n",
        "    recall = recall_score(y_test, y_hat)\n",
        "    accuracy = accuracy_score(y_test, y_hat)\n",
        "\n",
        "    print(\"Fold \",i)\n",
        "    print(\"Accuracy: \",accuracy)\n",
        "    print(\"Precision: \",precision)\n",
        "    print(\"Recall: \",recall)\n",
        "    print(\"---------------------------------\")"
      ],
      "metadata": {
        "id": "H4_rCS37vNDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 4**"
      ],
      "metadata": {
        "id": "4vCUIdCOnt-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(train,test,fold,k):\n",
        "  X_test, y_test = test.drop([test.columns[-1]], axis=1), test[test.columns[-1]]\n",
        "  X_train, y_train = train.drop([train.columns[-1]], axis=1), train[train.columns[-1]]\n",
        "  X_train = X_train.iloc[:,1:].to_numpy()\n",
        "  y_train = y_train.to_numpy()\n",
        "  X_test = X_test.iloc[:,1:].to_numpy()\n",
        "  y_test = y_test.to_numpy()\n",
        "  y_hat=[]\n",
        "  train = train.to_numpy()\n",
        "  for test in X_test:\n",
        "      distances = [np.linalg.norm(test - x) for x in X_train]\n",
        "      idx = np.argpartition(distances, k-1)[:k]\n",
        "      counter = Counter(y_train[idx])\n",
        "      y_hat.append(counter.most_common()[0][0])\n",
        "      \n",
        "      \n",
        "  precision = precision_score(y_test, y_hat)\n",
        "  recall = recall_score(y_test, y_hat)\n",
        "  accuracy = accuracy_score(y_test, y_hat)\n",
        "  return precision,accuracy,recall\n",
        "           \n",
        "\n",
        "data = pd.read_csv('emails.csv',sep=',')\n",
        "\n",
        "K = [1,3,5,7]\n",
        "Accuracy = []\n",
        "for k in K:\n",
        "    accuracy_array = []\n",
        "    for i in range(0,5):\n",
        "        test = data.iloc[i*1000:i*1000 + 1000, :]\n",
        "        train = data.drop(test.index)\n",
        "        accuracy = knn(train,test,i*1000,k)\n",
        "        accuracy_array.append(accuracy)\n",
        "    Accuracy.append(np.average(accuracy_array))\n",
        "\n",
        "plt.title(\"kNN 5-fold cross validation\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.plot(K,Accuracy)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oa9qb3eSnBgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 5**"
      ],
      "metadata": {
        "id": "fyxdrVWfoeJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(X_test,X_train,y_test_y_train, test, threshold,k=5):\n",
        "    X_train = X_train.iloc[:,1:].to_numpy()\n",
        "    y_train = y_train.to_numpy()\n",
        "    X_test = X_test.iloc[:,1:].to_numpy()\n",
        "    y_test = y_test.to_numpy()\n",
        "    y_hat=[]\n",
        "    train = train.to_numpy()\n",
        "    for test in X_test:\n",
        "        distances = [np.linalg.norm(test - x) for x in X_train]\n",
        "        idx = np.argpartition(distances, k-1)[:k]\n",
        "        counter = Counter(y_train[idx])\n",
        "        fraction = 0\n",
        "        if counter.get(1) != None:\n",
        "            fraction = (float)(counter.get(1)) / k\n",
        "        if (fraction >= threshold):\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            y_hat.append(0)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
        "    tpr = tp / (tp + fn)\n",
        "    fpr = fp / (tn + fp)\n",
        "    return tpr,fpr\n",
        "\n",
        "class LogisticRegression():\n",
        "    def __init__(self, alpha, iterations):\n",
        "        self.alpha = alpha\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.m, self.n = X.shape\n",
        "        self.W = np.zeros(self.n)\n",
        "        self.b = 0\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        for i in range(self.iterations):\n",
        "            self.weights_update()\n",
        "        return self\n",
        "\n",
        "    def weights_update(self):\n",
        "        A = 1 / (1 + np.exp(- (self.X.dot(self.W) + self.b)))\n",
        "\n",
        "        temp = (A - self.Y.T)\n",
        "        temp = np.reshape(temp, self.m)\n",
        "        dW = np.dot(self.X.T, temp) / self.m\n",
        "        db = np.sum(temp) / self.m\n",
        "\n",
        "        self.W = self.W - self.alpha * dW\n",
        "        self.b = self.b - self.alpha * db\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, threshold):\n",
        "        P = 1 / (1 + np.exp(- (X.dot(self.W) + self.b)))\n",
        "        Y = np.where(P >= threshold, 1, 0)\n",
        "        return Y\n",
        "\n",
        "\n",
        "def main():\n",
        "  #data\n",
        "    data = pd.read_csv('emails.csv', sep=',')\n",
        "    test = data.iloc[4000:5000, :]\n",
        "    train = data.drop(test.index)\n",
        "\n",
        "    X_train = train.iloc[:, 1:-1].values\n",
        "    X_test = test.iloc[:, 1:-1].values\n",
        "    y_train = train.iloc[:, -1:].values\n",
        "    y_test = test.iloc[:, -1:].values.ravel()\n",
        "  #Logistic regression\n",
        "    clf = LogisticRegression(alpha=0.01, iterations=3000)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    logistic_tpr = []\n",
        "    logistic_fpr = []\n",
        "    for threshold in np.arange(0, 1.1, 0.1):\n",
        "        y_hat = clf.predict(X_test, threshold)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
        "        logistic_tpr.append(tp / (tp + fn))\n",
        "        logistic_fpr.append(fp / (tn + fp))\n",
        "  #KNN\n",
        "    knn_tpr = []\n",
        "    knn_fpr = []\n",
        "    for threshold in np.arange(0, 1.1, 0.1):\n",
        "        tpr,fpr = knn( X_test,X_train,y_test,y_train, threshold)\n",
        "        knn_tpr.append(tpr)\n",
        "        knn_fpr.append(fpr)\n",
        "  #Plot\n",
        "    plt.plot(knn_fpr, knn_tpr, color='blue')\n",
        "    plt.plotlogistic_fpr, logistic_tpr, color='orange')\n",
        "\n",
        "    plt.xlabel(\"False Positive Rate (Positive label: 1)\")\n",
        "    plt.ylabel(\"False Positive Rate (Positive label: 1)\")\n",
        "    plt.legend(['KNeighborsClassifier', 'LogisticRegression'], loc=4)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "main()"
      ],
      "metadata": {
        "id": "JfsqtUg0of_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}