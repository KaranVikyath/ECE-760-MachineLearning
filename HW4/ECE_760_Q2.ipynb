{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tXutdq8BWRkl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
        "language = ['e','j','s']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kkT-MRGWRkl"
      },
      "source": [
        "### **Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ja2bllCLWRkm"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i,lang in enumerate(language):\n",
        "    for j in range(10):\n",
        "        with open(f\"languageID/{lang}{j}.txt\",'r+') as f:\n",
        "            txt = f.readlines()\n",
        "        txt = ''.join(txt)\n",
        "        txt = Counter(txt)\n",
        "        txt = [txt[i] for i in letters]\n",
        "        X_train.append(txt)\n",
        "        y_train.append(i)\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipIh6hx1WRkm",
        "outputId": "d8209e46-da85-44ce-d5b5-723007efe057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06016851 0.01113497 0.02151    0.02197258 0.10536924 0.01893276\n",
            " 0.01747894 0.04721626 0.05541054 0.00142078 0.00373369 0.02897737\n",
            " 0.02051875 0.05792169 0.0644639  0.01675202 0.0005617  0.05382455\n",
            " 0.06618206 0.08012556 0.02666446 0.00928465 0.01549645 0.00115645\n",
            " 0.01384437 0.00062779 0.17924996]\n"
          ]
        }
      ],
      "source": [
        "english = X_train[y_train == 0]\n",
        "english_count = np.sum(english,axis=0)\n",
        "english_count = english_count + 0.5\n",
        "e_probability = english_count/sum(english_count)\n",
        "print(e_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N50BXMMTWRkm"
      },
      "source": [
        "### **Question 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iziuFPgsWRkm",
        "outputId": "f00a0f05-3ca8-4d77-dbde-93b3dc166432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.31765610e-01 1.08669066e-02 5.48586603e-03 1.72263182e-02\n",
            " 6.02047591e-02 3.87854223e-03 1.40116706e-02 3.17621161e-02\n",
            " 9.70334393e-02 2.34110207e-03 5.74094133e-02 1.43261470e-03\n",
            " 3.97987351e-02 5.67105769e-02 9.11632132e-02 8.73545547e-04\n",
            " 1.04825466e-04 4.28037318e-02 4.21747790e-02 5.69901115e-02\n",
            " 7.06174220e-02 2.44592753e-04 1.97421294e-02 3.49418219e-05\n",
            " 1.41514379e-02 7.72214263e-03 1.23449457e-01]\n"
          ]
        }
      ],
      "source": [
        "japanese = X_train[y_train == 1]\n",
        "japanese_count = np.sum(japanese,axis=0)\n",
        "japanese_count = japanese_count + 0.5\n",
        "j_probability = japanese_count/sum(japanese_count)\n",
        "print(j_probability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCXuMEpZWRkn",
        "outputId": "34cae762-d4b3-483a-e366-bfd720167f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.04560451e-01 8.23286362e-03 3.75258241e-02 3.97459221e-02\n",
            " 1.13810860e-01 8.60287996e-03 7.18448398e-03 4.53270019e-03\n",
            " 4.98597021e-02 6.62945947e-03 2.77512257e-04 5.29431717e-02\n",
            " 2.58086399e-02 5.41765595e-02 7.24923684e-02 2.42669051e-02\n",
            " 7.67783910e-03 5.92951189e-02 6.57704049e-02 3.56140730e-02\n",
            " 3.37023219e-02 5.88942678e-03 9.25040856e-05 2.49761031e-03\n",
            " 7.86284728e-03 2.68261848e-03 1.68264932e-01]\n"
          ]
        }
      ],
      "source": [
        "spanish = X_train[y_train == 2]\n",
        "spanish_count = np.sum(spanish,axis=0)\n",
        "spanish_count = spanish_count + 0.5\n",
        "s_probability = spanish_count/sum(spanish_count)\n",
        "print(s_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "josFapoxWRkn"
      },
      "source": [
        "### Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skDJm2B_WRkn",
        "outputId": "d5520993-4cb7-4c38-caf4-2d317935ee1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[164, 32, 53, 57, 311, 55, 51, 140, 140, 3, 6, 85, 64, 139, 182, 53, 3, 141, 186, 225, 65, 31, 47, 4, 38, 2, 498]\n"
          ]
        }
      ],
      "source": [
        "with open(\"languageID/e10.txt\",'r+') as f:\n",
        "    txt = f.readlines()\n",
        "    txt = ''.join(txt)\n",
        "    txt = Counter(txt)\n",
        "\n",
        "bag_of_words = [txt[i] for i in letters]\n",
        "print(bag_of_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAOxfwDVWRkn"
      },
      "source": [
        "### Question 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFRtEQmOWRkn",
        "outputId": "a093f186-60fe-4007-e2c3-ab709516866a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7841.865447060635 -8467.282044010557 -8771.433079075032\n",
            "Predicted class is 'e'\n"
          ]
        }
      ],
      "source": [
        "eng = sum(bag_of_words*np.log(e_probability))\n",
        "spa = sum(bag_of_words*np.log(j_probability))\n",
        "jap = sum(bag_of_words*np.log(s_probability))\n",
        "print(eng, jap, spa)\n",
        "print(f\"Predicted class is \\'{language[np.argmax([eng, jap, spa])]}\\'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sg0vfxRWRko"
      },
      "source": [
        "### Question 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LjXTgmirWRko"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "for i,lang in enumerate(language):\n",
        "    for j in range(10,20):\n",
        "        with open(f\"languageID/{lang}{j}.txt\",'r+') as f:\n",
        "            txt = f.readlines()\n",
        "        txt = ''.join(txt)\n",
        "        txt = Counter(txt)\n",
        "        txt = [txt[i] for i in letters]\n",
        "        X_test.append(txt)\n",
        "        y_test.append(i)\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "tbSgoDBdWRko"
      },
      "outputs": [],
      "source": [
        "y_hat = []\n",
        "for x in X_test:\n",
        "    eng = sum(x*np.log(e_probability))\n",
        "    spa = sum(x*np.log(s_probability))\n",
        "    jap = sum(x*np.log(j_probability))\n",
        "    y_hat.append(np.argmax([eng, jap, spa]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlqIw767WRko",
        "outputId": "7d269d4d-e392-44d2-efc3-195887d18e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\tEng\tJap\tSpa\n",
            "Eng\t10\t0\t0\n",
            "Jap\t0\t10\t0\n",
            "Spa\t0\t0\t10\n"
          ]
        }
      ],
      "source": [
        "print(\"Confusion Matrix\")\n",
        "print(\"\\tEng\\tJap\\tSpa\")\n",
        "confmat = confusion_matrix(y_test,y_hat)\n",
        "print(f\"Eng\\t{confmat[0][0]}\\t{confmat[0][1]}\\t{confmat[0][2]}\")\n",
        "print(f\"Jap\\t{confmat[1][0]}\\t{confmat[1][1]}\\t{confmat[1][2]}\")\n",
        "print(f\"Spa\\t{confmat[2][0]}\\t{confmat[2][1]}\\t{confmat[2][2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OyrKLCwWRko"
      },
      "source": [
        "### Question 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkvIXISwWRko",
        "outputId": "f9a2b50f-342b-45b7-fc81-2e35cd5c280a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Original Text===\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " quedarse dormido en el trabajo \n",
            "\n",
            " esparcir rumores sobre un colega\n",
            "\n",
            "el contorno de los ojos piel extremadamente fragil padece multiples problemas esteticos capaces de arruinar la expresividad felicidad carrera directora del prestigioso centro de estetica que lleva su nombre y asesora experta de la firma olay asegura que el contorno de ojos necesita un producto especifico ya que la piel de esa zona es sensible y muy fragil\n",
            "\n",
            "jamas de debe olvidar desmaquillar los ojos por la manana y por la noche especialmente si se maquillan eye makeup remover de lancaster limpia la zona perfectamente y su formula incluye propiedades calmantes resultan muy practicas sobre todo si viaja  las toallitas desmaquilladoras de olay que no dejan ni rastro de maquillaje\n",
            "\n",
            "     compras productos para los ojos de olay\n",
            "\n",
            "pequenas lineas de expresion o patas de gallo se debe aplicar crema de contorno de ojos antiedad la firma roc propone retinox correccion ojos un complejo mineral energizante que actua estimulando la sintesis del colageno de la piel reduciendo visiblemente la profanidad de las arrugas para olay es imprescindible aplicar el contorno de ojos effects x de olay sujetando la piel del contorno de ojos con el fin de que se abran las lineas de expresion y patas de gallo a la vez que se extiende el producto se realizan masajes circulares con la yema del dedo anular durante  segundos de este modo el producto penetra mejor\n",
            "\n",
            "ojos hundidos para elevar la mirada sera necesario aplicar una sombra clara desde las cejas hasta las pestanas y otra oscura encima del pliegue del parpado con el fin de reducir optimamente el hueso orbital si se traza una linea muy fina color marron sobre las pestanas la mirada se realza se deben evitar los tonos perlados bajo la ceja  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===Shuffeled Text===\n",
            "tlrrqe j s  cup sluia o aasm  n motoanimeo rduqe tseeengreclcesdptsreoiu eavz  elidnuapasdem do merebeois ldcblar sedr eeio  aerdae dfozlnbaatd\n",
            "iaa n n lpd e l oul  p p esasaae a\n",
            "a\n",
            "eaavt dodpoliesclddp l   mldtold  e paaaarcui\n",
            "as ll dadtosri esrocarao epicen o duo jsred nacna airt dem ir elun dsahxsc \n",
            "tp iatattd qnldqjsslalld tdbsioupehtcasau dyllee t   enrmiaasb nar rme ynre bddib l rrsfddsa\n",
            "oia  aloeotetn lul mla\n",
            "ao\n",
            " eiess aenucaeo gbrtindnneycsrep as tc da xnreeoqoc esic ldlbelne  vj aeolroeedcj str lonid d dmoan rlets efro mpsp sfoaaiois ep\n",
            "sa euqmcjzscuicocnu eseacee oaaeod pl faeagatemopciialjp\n",
            "eri s  bstoeel s si heipmset jeealeo nnt aeo  ueood  \n",
            "etsseryzilrlricespatd isprpoen  nusa anltornmorr ylroaueytsnarile n nuirom arx inssn mr r sa a nmf\n",
            " a uerlmelppiecacrypeapynsdv fssraicasdrdoors  rcoo ee dtnalir  \n",
            "os ocnis\n",
            "gennbc  aeaaa s srno   iiiilnamrfaa eo y\n",
            "\n",
            " amilaoil  nioese erey qjoa edse saiu re  o  pnnsl co p ma  t st   yayls ziouoaljiaen\n",
            " meqddtfdssyse sn\n",
            "rocliye sehaaaaa tcnaepioroaseuac cbi st arecnsdonexa elltaor i to do eeere moeea aap r cr aprca ualax so xern daleprev ddejor dejnouse nc o olat o elraodclae alqo a eeaundgl\n",
            " sdndr o adcap zaaspdpu\n",
            "fauelgplosuoozemalr e pleqsesur e als caacnoiraimroe oeooaclraojorlm i\n",
            "e llt mumq u iapuruqreo ecjaasa l\n",
            " m tei e illicoij gdttiyibdllnnnea ec  keoene nuipsr dy oo evlaaa la mdaoe\n",
            "qoitbv  eo\n",
            "oe  leeparo aa  dcserae s e rjl movar  eu risnoe adev o \n",
            "c sra unun anco p reepoeesn \n",
            "lo  eejlarpsetcaeasdor cer reitm csm  aoa mnul m\n",
            "germtes s aodtrmieil o upcaessdlfltaet crasn\n",
            "rejio ldlee\n",
            "ogeane j edetacanro uyrelsrtlsirslaaedud lupgpddspn etpguasaeaie en  uigraloarfliia reiei saalx  ombooeearj i roso ayerutnbcilj eetta t  rfasone ear ols  oeafeemodal inaer   amuncleeuoanecedlla oo tsnloeee\n",
            " mepdx lpr\n",
            "\n",
            "====================\n",
            "\n",
            "-5138.612351415966 -5791.859741543933 -4865.532135355225\n",
            "Predicted class is 's'\n"
          ]
        }
      ],
      "source": [
        "with open(\"languageID/s3.txt\",'r+') as f:\n",
        "    txt = f.readlines()\n",
        "    txt = ''.join(txt)\n",
        "    print(\"===Original Text===\")\n",
        "    print(txt)\n",
        "    temp = list(txt)\n",
        "    random.shuffle(temp)\n",
        "    txt = ''.join(temp)\n",
        "    print(\"===Shuffeled Text===\")\n",
        "    print(txt)\n",
        "    txt = Counter(txt)\n",
        "print(\"\\n====================\\n\")\n",
        "bag_of_words = [txt[i] for i in letters]\n",
        "\n",
        "eng = sum(bag_of_words*np.log(e_probability))\n",
        "spa = sum(bag_of_words*np.log(s_probability))\n",
        "jap = sum(bag_of_words*np.log(j_probability))\n",
        "print(eng, jap, spa)\n",
        "print(f\"Predicted class is \\'{language[np.argmax([eng, jap, spa])]}\\'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}